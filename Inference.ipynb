{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)       \n",
    "    img = ds.pixel_array\n",
    "    \n",
    "    # Check validity\n",
    "    if ds['PatientPosition'].value not in ['AP', 'PA']:\n",
    "        print('Image position ({}) invalid'.format(ds['PatientPosition'].value))\n",
    "        return None\n",
    "    elif ds['BodyPartExamined'].value.lower() != 'chest':\n",
    "        print('Body part ({}) invalid'.format(ds['BodyPartExamined'].value))\n",
    "        return None\n",
    "    elif ds['Modality'].value != 'DX':\n",
    "        print('Image type ({}) invalid'.format(ds['Modality'].value))\n",
    "    \n",
    "    return img\n",
    "\n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_mean, img_std, img_size): \n",
    "    img = (img - img_mean) / img_std\n",
    "    \n",
    "    proc_img = resize(img, img_size)\n",
    "    \n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # Load architecture from JSON\n",
    "    json_file = open(model_path, 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = keras.models.model_from_json(model_json)\n",
    "    \n",
    "    # Load weights from hdf5\n",
    "    model.load_weights(weight_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    prediction = (model.predict(img) > thresh)\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file test1.dcm ...\n",
      "[[ True]]\n",
      "Load file test2.dcm ...\n",
      "[[ True]]\n",
      "Load file test3.dcm ...\n",
      "[[ True]]\n",
      "Load file test4.dcm ...\n",
      "Body part (RIBCAGE) invalid\n",
      "Load file test5.dcm ...\n",
      "Image type (CT) invalid\n",
      "[[ True]]\n",
      "Load file test6.dcm ...\n",
      "Image position (XX) invalid\n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = 'my_model.json'\n",
    "weight_path = 'xray_class_my_model.best.hdf5'\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "\n",
    "'''\n",
    "I did not use a constant image mean and standard deviation for model training.\n",
    "I took the mean and std of each image using samplewise scaling with ImageDataGenerator \n",
    "(as suggested in Mentor Help), and so to keep inference consistent with training,\n",
    "here I take the mean and std of each test image separately.\n",
    "'''\n",
    "# img_mean = # loads the mean image value they used during training preprocessing\n",
    "# img_std = # loads the std dev image value they used during training preprocessing\n",
    "\n",
    "my_model = load_model(model_path, weight_path)\n",
    "thresh = 0.5616551041603088\n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_mean = img.mean()\n",
    "    img_std = img.std()\n",
    "    \n",
    "    img_proc = preprocess_image(img, img_mean, img_std, IMG_SIZE)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
